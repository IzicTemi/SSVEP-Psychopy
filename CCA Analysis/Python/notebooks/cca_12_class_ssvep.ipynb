{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12-Class SSVEP Dataset\n",
    "## Classification Using Canonical Correaltion Analysis (CCA)\n",
    "### The following is implemented on a 12-Class publicly available SSVEP EEG Dataset\n",
    "\n",
    "<img src=\"../images/12_classSSVEP.png\">\n",
    "\n",
    "#### Dataset URL: \n",
    "https://github.com/mnakanishi/12JFPM_SSVEP/tree/master/data\n",
    "\n",
    "#### Dataset Paper:\n",
    "Masaki Nakanishi, Yijun Wang, Yu-Te Wang and Tzyy-Ping Jung, \n",
    "\"A Comparison Study of Canonical Correlation Analysis Based Methods for Detecting Steady-State Visual Evoked Potentials,\" \n",
    "PLoS One, vol.10, no.10, e140703, 2015. \n",
    "\n",
    "#### Implementation:\n",
    "Note: Following implementation is an asynchronous SSVEP BCI using CCA classification for 1 second data length\n",
    "\n",
    "Aravind Ravi | eBionics Lab | University of Waterloo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath('..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from scripts import ssvep_files as su"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Canonical Correlation Analysis (CCA)\n",
    "$$\\DeclareMathOperator*{\\argmax}{argmax}$$\n",
    "\n",
    "Consider two multidimensional variables $X$, $Y$ where $X$ refers to the set of multi-channel EEG data and $Y$ refers to the set of reference signals of the same length as $X$. The linear combinations of $X$ and $Y$ are given as $x = X'W_{x}$ and $y = Y'W_{y}$. CCA finds the weights, $W_{x}$ and $W_{y}$ that maximize the correlation between $x$ and $y$ by solving (1). The maximum of $\\rho$ with respect to $W_{x}$ and $W_{y}$ is the maximum correlation.\n",
    "\n",
    "$$\\max_{W_{x},W_{y}} \\rho(x,y) = \\frac{\\mathbb{E}{[W_{x}'XY'W_{y}]}}{\\sqrt{\\mathbb{E}{[W_{x}'XX'W_{x}]}\\mathbb{E}{[W_{y}'YY'W_{y}]}}}$$\n",
    "\n",
    "The reference signals $Y_{n}$  are defined as:\n",
    "\n",
    "$$Y_{n} = \\begin{bmatrix} \\sin({2 \\pi f_{n}t}) \\\\ \\cos({2 \\pi f_{n}t}) \\\\ \\vdots \\\\ \\sin({4 \\pi  f_{n}t}) \\\\ \\cos({4 \\pi  f_{n}t}) \\end{bmatrix},t = \\begin{bmatrix} \n",
    "    \\frac{1}{f_{s}}\n",
    "    \\frac{2}{f_{s}}\n",
    "    \\dots\n",
    "    \\frac{N_{s}}{f_{s}}\n",
    "    \\end{bmatrix}$$\n",
    "    \n",
    "where $Y_{n} \\in \\mathbb{R}^{2 N_{h} \\times N_{s}} $, $f_{n}$ is the stimulation frequency, $f_{s}$ is the sampling frequency, $N_{s}$ is number of samples, and $N_{h}$ is the number of harmonics. Here, $N_{h}=2$. The canonical correlation features $\\rho_{f_{i}}$, where $i = 1,2,...,7$ are extracted for each segment of the EEG data, and the output class $C$ for a given sample can be determined as: $C = \\argmax (\\rho_{f_{i}})$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.abspath('../Dataset')\n",
    "all_segment_data = dict()\n",
    "all_acc = list()\n",
    "window_len = 1\n",
    "shift_len = 0.14\n",
    "sample_rate = 250\n",
    "duration = int(window_len*sample_rate)\n",
    "flicker_freq = np.array([9.25, 11.25, 13.25, 9.75, 11.75, 13.75, \n",
    "                       10.25, 12.25, 14.25, 10.75, 12.75, 14.75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cca_reference_signals(data_len, target_freq, sampling_rate):\n",
    "    reference_signals = []\n",
    "    t = np.arange(0, (data_len/(sampling_rate)), step=1.0/(sampling_rate))\n",
    "    reference_signals.append(np.sin(np.pi*2*target_freq*t))\n",
    "    reference_signals.append(np.cos(np.pi*2*target_freq*t))\n",
    "    reference_signals.append(np.sin(np.pi*4*target_freq*t))\n",
    "    reference_signals.append(np.cos(np.pi*4*target_freq*t))\n",
    "    reference_signals = np.array(reference_signals)\n",
    "    \n",
    "    return reference_signals\n",
    "\n",
    "def find_correlation(n_components, np_buffer, freq):\n",
    "    cca = CCA(n_components)\n",
    "    corr = np.zeros(n_components)\n",
    "    result = np.zeros(freq.shape[0])\n",
    "    for freq_idx in range(0,freq.shape[0]):\n",
    "        cca.fit(np_buffer.T,np.squeeze(freq[freq_idx, :, :]).T)\n",
    "        O1_a,O1_b = cca.transform(np_buffer.T, np.squeeze(freq[freq_idx, :, :]).T)\n",
    "        ind_val = 0\n",
    "        for ind_val in range(0,n_components):\n",
    "            corr[ind_val] = np.corrcoef(O1_a[: ,ind_val], O1_b[:, ind_val])[0 ,1]\n",
    "            result[freq_idx] = np.max(corr)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def cca_classify(segmented_data, reference_templates):\n",
    "    predicted_class = []\n",
    "    labels = []\n",
    "    for target in range(0, segmented_data.shape[0]):\n",
    "        for trial in range(0, segmented_data.shape[2]):\n",
    "            for segment in range(0, segmented_data.shape[3]):\n",
    "                labels.append(target)\n",
    "                result = find_correlation(1, segmented_data[target, :, trial, segment, :], \n",
    "                                      reference_templates)\n",
    "                predicted_class.append(np.argmax(result)+1)\n",
    "    labels = np.array(labels)+1\n",
    "    predicted_class = np.array(predicted_class)\n",
    "\n",
    "    return labels, predicted_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset = sio.loadmat(f'{data_path}/s001.mat')\n",
    "eeg = np.array(dataset['data'], dtype='float32')\n",
    "eeg = eeg[:,:,1,:,:]\n",
    "eeg = np.squeeze(eeg)\n",
    "eeg = eeg.reshape(12,8,710,10)\n",
    "    \n",
    "num_classes = eeg.shape[0]\n",
    "num_chan = eeg.shape[1]\n",
    "total_trial_len = eeg.shape[2]\n",
    "num_trials = eeg.shape[3]\n",
    "   \n",
    "trial_len = int(125+0.14*sample_rate+2*sample_rate+0.2*sample_rate-1) - int(125+0.14*sample_rate) - int(0.2*sample_rate)\n",
    "filtered_data = np.zeros((eeg.shape[0], eeg.shape[1], trial_len, eeg.shape[3]))\n",
    "\n",
    "for target in range(0, num_classes):\n",
    "    for channel in range(0, num_chan):\n",
    "        for trial in range(0, num_trials):\n",
    "            signal_to_filter = np.squeeze(eeg[target, channel, int(125+0.14*sample_rate):\n",
    "                                            int(125+0.14*sample_rate+2*sample_rate+0.2*sample_rate-1) - int(0.2*sample_rate), \n",
    "                                            trial])\n",
    "            \n",
    "signal_to_filter.shape\n",
    "filtered_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset, filter and segment epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in np.arange(1, 103):\n",
    "    dataset = sio.loadmat(f'{data_path}/s{subject:03}.mat')\n",
    "    eeg = np.array(dataset['data'], dtype='float32')\n",
    "    eeg = eeg[:,:,1,:,:]\n",
    "    eeg = np.squeeze(eeg)\n",
    "    eeg = eeg.reshape(12,8,710,10)\n",
    "    \n",
    "    num_classes = eeg.shape[0]\n",
    "    n_ch = eeg.shape[1]\n",
    "    total_trial_len = eeg.shape[2]\n",
    "    num_trials = eeg.shape[3]\n",
    "    \n",
    "    filtered_data = su.get_filtered_eeg(eeg, 7.25, 90, 2, sample_rate)\n",
    "    all_segment_data[f's{subject:03}'] = su.get_segmented_epochs(filtered_data, window_len, \n",
    "                                                           shift_len, sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating the required sinusoidal templates for the given 12-class SSVEP classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_templates = []\n",
    "for fr in range(0, len(flicker_freq)):\n",
    "    reference_templates.append(get_cca_reference_signals(duration, flicker_freq[fr], sample_rate))\n",
    "reference_templates = np.array(reference_templates, dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform CCA on the segmented epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'=' alignment not allowed in string format specifier",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\Desktop\\Brain-computer-interfaces\\notebooks\\cca_12_class_ssvep.ipynb Cell 13'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Desktop/Brain-computer-interfaces/notebooks/cca_12_class_ssvep.ipynb#ch0000014?line=3'>4</a>\u001b[0m accuracy \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdivide(np\u001b[39m.\u001b[39mtrace(c_mat), np\u001b[39m.\u001b[39msum(np\u001b[39m.\u001b[39msum(c_mat)))\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Desktop/Brain-computer-interfaces/notebooks/cca_12_class_ssvep.ipynb#ch0000014?line=4'>5</a>\u001b[0m all_acc\u001b[39m.\u001b[39mappend(accuracy)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Desktop/Brain-computer-interfaces/notebooks/cca_12_class_ssvep.ipynb#ch0000014?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mSubject: \u001b[39m\u001b[39m{\u001b[39;00msubject\u001b[39m:\u001b[39;00m\u001b[39m03\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, Accuracy: \u001b[39m\u001b[39m{\u001b[39;00maccuracy\u001b[39m*\u001b[39m\u001b[39m100\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m %\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: '=' alignment not allowed in string format specifier"
     ]
    }
   ],
   "source": [
    "for subject in all_segment_data.keys():\n",
    "    labels, predicted_class = cca_classify(all_segment_data[subject], reference_templates)\n",
    "    c_mat = confusion_matrix(labels, predicted_class)\n",
    "    accuracy = np.divide(np.trace(c_mat), np.sum(np.sum(c_mat)))\n",
    "    all_acc.append(accuracy)\n",
    "    print(f'Subject: {subject:03}, Accuracy: {accuracy*100} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy Across Subjects: 63.22222222222222 %, std: 21.665580457103147 %\n"
     ]
    }
   ],
   "source": [
    "all_acc = np.array(all_acc)\n",
    "print(f'Overall Accuracy Across Subjects: {np.mean(all_acc)*100} %, std: {np.std(all_acc)*100} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "783px",
    "left": "1528px",
    "right": "20px",
    "top": "115px",
    "width": "387px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
